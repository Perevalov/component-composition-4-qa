{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from rdflib import Graph, Namespace, RDF\n",
    "\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from scripts.annotations import AnnotationQuestion, AnnotationOfInstance, AnnotationOfRelation, AnnotationOfAnswerSPARQL\n",
    "from scripts.functions import parse_component, reachable, find_output_annotation_in_combination\n",
    "\n",
    "data_dir = \"./data/\"\n",
    "descriptions_dir = os.path.join(data_dir, \"component-descriptions\")\n",
    "\n",
    "# Define the namespaces used in the RDF/Turtle file\n",
    "QA = Namespace('https://w3id.org/wdaqua/qanary#')\n",
    "RDFS = Namespace('http://www.w3.org/2000/01/rdf-schema#')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse RDF-descriptions into Python objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_files = os.listdir(descriptions_dir) # load all rdf description file names in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = []\n",
    "\n",
    "for file in description_files: # iterate over available component descriptions\n",
    "\n",
    "    # Load the RDF/Turtle file into an rdflib graph\n",
    "    try:\n",
    "        g = Graph()\n",
    "        with open(os.path.join(descriptions_dir, file), 'r') as f:\n",
    "            g.parse(f, format='turtle')\n",
    "\n",
    "        # Find the component type\n",
    "        component_type = [t for t in g.triples((QA[file.replace('.ttl', '')], RDF.type, None))][0][2].toPython()\n",
    "        # Find the component in the graph\n",
    "        component_uri = QA[file.replace('.ttl', '')]\n",
    "        component = parse_component(g, component_uri, component_type)\n",
    "        components.append(component)\n",
    "    except Exception as e:\n",
    "        print(file)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following components are there: [PythonMBart, OpentapiocaNED, TextRazorNER, TagMeNED, CLSNLIOD, AmbiverseNED, MeaningCloudNER, StanfordNER, LDShuyo, ComicCharacterNameSimpleNER, MeaningCloudNED, PythonLibreTranslate, DBpediaSpotlightNED, PythonNLLB, BabelfyNED, EntityClassifier2NER, Sina, PythonHelsinkiNLP, WatsonNED, AGDISTISNED, ReMatch, QAnswer, DandelionNER, AylienNER, DBpediaSpotlightNER, DandelionNED, OntotextNER, BabelfyNER, AylienNED, FoxNER, AmbiverseNER, TagMeNER, OntotextNED]\n"
     ]
    }
   ],
   "source": [
    "print(\"The following components are there:\", components)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create all the possible combinations of the components\n",
    "\n",
    "### 1. Permutation of types\n",
    "\n",
    "How many ways can you place $n$ different objects in $k$ different places ($k$ $\\in$ $1,2,\\ldots,n$)?\n",
    "\n",
    "\\begin{equation}\n",
    "P^k_n = \\frac{n!}{(n-k)!}\n",
    "\\end{equation}\n",
    "\n",
    "Where $n$ is a number of types and $k$ is a number of abstract components in a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_component_dict = {}\n",
    "\n",
    "# construct a dictionary mapping component types to actual components that have that type\n",
    "for component in components:\n",
    "    type_component_dict[type(component)] = type_component_dict.get(type(component), []) + [component]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_permutations_dict = {}\n",
    "\n",
    "# construct a dictionary mapping the length of a permutation to all possible permutations of component types\n",
    "for k in range(1, len(type_component_dict.keys()) + 1):\n",
    "    len_permutations_dict[k] = [p for p in permutations(type_component_dict.keys(), k)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Permutation of components within a permutation of types\n",
    "\n",
    "Let $k$ actions be performed sequentially. If the first action can be performed in $n_1$ ways, the second action in $n_2$ ways, the third action in $n_3$ ways, and so on to the $k$-th. Then the total number of ways in which the $k$ actions can be performed is:\n",
    "\n",
    "\\begin{equation}\n",
    "N = n_1*n_2*...*n_k\n",
    "\\end{equation}\n",
    "\n",
    "Where $n_i$ is a number of actual components of the $i$-th type (e.g., NER, REL, QB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_lists(lists):\n",
    "    \"\"\"\n",
    "    Combines the provided list of lists into a list of tuples, where each tuple contains a component combination.\n",
    "    N = n_1*n_2*...*n_k, where n_i is the length of the i-th list in lists and k is the length of the lists.\n",
    "\n",
    "    Args:\n",
    "        lists (_type_): a list of lists of actual components\n",
    "\n",
    "    Returns:\n",
    "        list: a list of tuples of actual components (combinations)\n",
    "    \"\"\"\n",
    "    if not lists:\n",
    "        return []\n",
    "    elif len(lists) == 1:\n",
    "        return [(x,) for x in lists[0]]\n",
    "    else:\n",
    "        result = []\n",
    "        for item in lists[0]:\n",
    "            for subitem in combine_lists(lists[1:]):\n",
    "                result.append((item,) + subitem)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = []\n",
    "for length, abstract_perm in len_permutations_dict.items():\n",
    "    for perm in abstract_perm:\n",
    "        component_type_lists = [type_component_dict[component_type] for component_type in perm]\n",
    "        combinations += combine_lists(component_type_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9956021"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combinations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping the combinations to Petri Net semantics with SNAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snakes.nets import *\n",
    "\n",
    "BATCH_SIZE = 3 * 10 ** 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nets_batch(combinations: list):\n",
    "    nets = []\n",
    "\n",
    "    for combination in combinations: # a single combination refers to a single petri net\n",
    "        n = PetriNet(' --> '.join(str(c) for c in combination))\n",
    "        \n",
    "        n.add_place(Place('questionPlace', [1, 'http://id.loc.gov/vocabulary/iso639-1/en'])) # assume english question on start\n",
    "\n",
    "        for component in combination:\n",
    "            place_name = str(component) + 'Place'\n",
    "            transition_name = str(component) + 'Transition'\n",
    "            n.add_place(Place(place_name, []))\n",
    "            n.add_transition(Transition(name=transition_name, guard=Expression(' and '.join([a.get_guard_expression() for a in component.input_annotations]))))\n",
    "            \n",
    "        prev_variables = []\n",
    "        for i in range(len(combination)):\n",
    "            input_variables = list(set([v for ia in combination[i].input_annotations for v in ia.get_input_variables()]))\n",
    "            input_variables = [v for v in prev_variables if v not in input_variables and type(v) != Value] + input_variables # add those prev_variables that are not in input_variables\n",
    "            output_values = list(set([v for oa in combination[i].output_annotations for v in oa.get_output_values()]))\n",
    "            \n",
    "            n.add_input(n.place()[i].name, n.transition()[i].name, MultiArc(input_variables))\n",
    "            n.add_output(n.place()[i + 1].name, n.transition()[i].name, MultiArc(input_variables + output_values))\n",
    "            \n",
    "            output_variables = list(set([v for oa in combination[i].output_annotations for v in oa.get_output_variables()]))\n",
    "            prev_variables = input_variables + output_variables\n",
    "\n",
    "        nets.append(n)\n",
    "    \n",
    "    return nets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce the reachable combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755b88845caa4c2a9d54aaec45f600c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/332 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08170cb8cd6b407696ed5dee0f47e015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAnswer Success!\n",
      "PythonMBart --> QAnswer Success!\n",
      "PythonNLLB --> QAnswer Success!\n",
      "PythonHelsinkiNLP --> QAnswer Success!\n",
      "OpentapiocaNED --> QAnswer Success!\n",
      "TagMeNED --> QAnswer Success!\n",
      "AmbiverseNED --> QAnswer Success!\n",
      "MeaningCloudNED --> QAnswer Success!\n",
      "DBpediaSpotlightNED --> QAnswer Success!\n",
      "BabelfyNED --> QAnswer Success!\n",
      "WatsonNED --> QAnswer Success!\n",
      "DandelionNED --> QAnswer Success!\n",
      "AylienNED --> QAnswer Success!\n",
      "OntotextNED --> QAnswer Success!\n",
      "TextRazorNER --> QAnswer Success!\n",
      "MeaningCloudNER --> QAnswer Success!\n",
      "StanfordNER --> QAnswer Success!\n",
      "ComicCharacterNameSimpleNER --> QAnswer Success!\n",
      "EntityClassifier2NER --> QAnswer Success!\n",
      "DandelionNER --> QAnswer Success!\n",
      "AylienNER --> QAnswer Success!\n",
      "DBpediaSpotlightNER --> QAnswer Success!\n",
      "OntotextNER --> QAnswer Success!\n",
      "BabelfyNER --> QAnswer Success!\n",
      "FoxNER --> QAnswer Success!\n",
      "AmbiverseNER --> QAnswer Success!\n",
      "TagMeNER --> QAnswer Success!\n",
      "CLSNLIOD --> QAnswer Success!\n",
      "LDShuyo --> QAnswer Success!\n",
      "QAnswer --> PythonMBart Success!\n",
      "QAnswer --> PythonLibreTranslate Success!\n",
      "QAnswer --> PythonNLLB Success!\n",
      "QAnswer --> PythonHelsinkiNLP Success!\n",
      "QAnswer --> OpentapiocaNED Success!\n",
      "QAnswer --> TagMeNED Success!\n",
      "QAnswer --> AmbiverseNED Success!\n",
      "QAnswer --> MeaningCloudNED Success!\n",
      "QAnswer --> DBpediaSpotlightNED Success!\n",
      "QAnswer --> BabelfyNED Success!\n",
      "QAnswer --> WatsonNED Success!\n",
      "QAnswer --> AGDISTISNED Success!\n",
      "QAnswer --> DandelionNED Success!\n",
      "QAnswer --> AylienNED Success!\n",
      "QAnswer --> OntotextNED Success!\n",
      "QAnswer --> TextRazorNER Success!\n",
      "QAnswer --> MeaningCloudNER Success!\n",
      "QAnswer --> StanfordNER Success!\n",
      "QAnswer --> ComicCharacterNameSimpleNER Success!\n",
      "QAnswer --> EntityClassifier2NER Success!\n",
      "QAnswer --> DandelionNER Success!\n",
      "QAnswer --> AylienNER Success!\n",
      "QAnswer --> DBpediaSpotlightNER Success!\n",
      "QAnswer --> OntotextNER Success!\n",
      "QAnswer --> BabelfyNER Success!\n",
      "QAnswer --> FoxNER Success!\n",
      "QAnswer --> AmbiverseNER Success!\n",
      "QAnswer --> TagMeNER Success!\n",
      "QAnswer --> CLSNLIOD Success!\n",
      "QAnswer --> LDShuyo Success!\n",
      "QAnswer --> ReMatch Success!\n",
      "ReMatch --> QAnswer Success!\n",
      "PythonMBart --> OpentapiocaNED --> QAnswer Success!\n",
      "PythonMBart --> TagMeNED --> QAnswer Success!\n",
      "PythonMBart --> AmbiverseNED --> QAnswer Success!\n",
      "PythonMBart --> MeaningCloudNED --> QAnswer Success!\n",
      "PythonMBart --> DBpediaSpotlightNED --> QAnswer Success!\n",
      "PythonMBart --> BabelfyNED --> QAnswer Success!\n",
      "PythonMBart --> WatsonNED --> QAnswer Success!\n",
      "PythonMBart --> DandelionNED --> QAnswer Success!\n",
      "PythonMBart --> AylienNED --> QAnswer Success!\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(0, len(combinations), BATCH_SIZE)): # we use a batch size to avoid memory issues\n",
    "    if i + BATCH_SIZE > len(combinations):\n",
    "        nets = create_nets_batch(combinations[i:])\n",
    "    else:\n",
    "        nets = create_nets_batch(combinations[i:i + BATCH_SIZE])\n",
    "    \n",
    "    for i in tqdm(range(len(nets))):\n",
    "        annotation = AnnotationOfAnswerSPARQL # search for this as a produced token in the net\n",
    "        if find_output_annotation_in_combination(annotation, combinations[i]): # theoretical possibility that the annotation is in the combination\n",
    "            if reachable(nets[i], annotation.token_value):\n",
    "                print(nets[i], \"Success!\")\n",
    "    \n",
    "    del nets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests / Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_combinations = []\n",
    "\n",
    "for i in range(len(combinations)):\n",
    "    comb_str = ' --> '.join(str(c) for c in combinations[i])\n",
    "    components = [\"DBpediaSpotlight\", \"ReMatch\", \"Sina\"]\n",
    "    \n",
    "    if all(c in comb_str for c in components):\n",
    "        test_combinations.append(combinations[i])\n",
    "        print(comb_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_combinations[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combination = test_combinations[3]\n",
    "\n",
    "n = PetriNet(' --> '.join(str(c) for c in combination))\n",
    "# define places\n",
    "n.add_place(Place('questionPlace', [1, 'https://w3id.org/wdaqua/qanary/English']))\n",
    "\n",
    "for component in combination:\n",
    "    place_name = str(component) + 'Place'\n",
    "    transition_name = str(component) + 'Transition'\n",
    "    n.add_place(Place(place_name, []))\n",
    "    n.add_transition(Transition(name=transition_name, guard=Expression(' and '.join([a.get_guard_expression() for a in component.input_annotations]))))\n",
    "    \n",
    "prev_variables = []\n",
    "for i in range(len(combination)):\n",
    "    input_variables = list(set([v for ia in combination[i].input_annotations for v in ia.get_input_variables()]))\n",
    "    input_variables = [v for v in prev_variables if v not in input_variables and type(v) != Value] + input_variables # add those prev_variables that are not in input_variables\n",
    "    output_values = list(set([v for oa in combination[i].output_annotations for v in oa.get_output_values()]))\n",
    "    \n",
    "    n.add_input(n.place()[i].name, n.transition()[i].name, MultiArc(input_variables))\n",
    "    n.add_output(n.place()[i + 1].name, n.transition()[i].name, MultiArc(input_variables + output_values))\n",
    "    \n",
    "    output_variables = list(set([v for oa in combination[i].output_annotations for v in oa.get_output_variables()]))\n",
    "    prev_variables = input_variables + output_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marking_value = AnnotationOfAnswerSPARQL.token_value\n",
    "\n",
    "n = test_nets[3]\n",
    "\n",
    "for transition in n.transition():\n",
    "    if len(transition.modes()) == 0: # deadlock\n",
    "        break\n",
    "    \n",
    "    transition.fire(transition.modes()[0])\n",
    "\n",
    "    for t in n.get_marking().keys():\n",
    "        if marking_value in n.get_marking()[t].items():\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
